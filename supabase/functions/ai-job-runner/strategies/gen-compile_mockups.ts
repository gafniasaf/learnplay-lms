
// AUTO-GENERATED by scaffold-manifest.ts
import { JobExecutor, JobContext } from './types.ts';

export class GeneratedCompileMockups implements JobExecutor {
  async execute(context: JobContext): Promise<any> {
    const { payload } = context;
    
    // 1. Interpolate Prompt
    let prompt = `Compile supplied mockup HTML into React routes. Ensure every data-cta-id is preserved. Return JSON {"success": boolean, "files_generated": string[], "errors": string[]}.`;
    // Basic interpolation
    if (payload) {
        Object.keys(payload).forEach(key => {
        const val = typeof payload[key] === 'object' ? JSON.stringify(payload[key]) : String(payload[key] ?? '');
        prompt = prompt.replace(new RegExp('{{' + key + '}}', 'g'), val);
        });
    }

    // 2. Call LLM (Simplified for seed)
    // Assuming OpenAI is configured in the runner environment
    const apiKey = Deno.env.get('OPENAI_API_KEY');
    if (!apiKey) {
       throw new Error("Blocked: OpenAI key missing. Please set OPENAI_API_KEY in your Edge Function secrets.");
    }

    try {
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify({
      model: 'gpt-5',
            messages: [{ role: 'system', content: prompt }],
            response_format: { type: "json_object" } 
        })
        });

        if (!response.ok) {
        const err = await response.text();
        throw new Error(`LLM Call Failed: ${err}`);
        }

        const data = await response.json();
        try {
            return JSON.parse(data.choices[0].message.content);
        } catch (e) {
            return { raw: data.choices[0].message.content };
        }
    } catch (err: unknown) {
        console.error(err);
        return { error: err instanceof Error ? err.message : String(err) };
    }
  }
}
